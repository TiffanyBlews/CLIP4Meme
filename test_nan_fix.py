#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯NaNé—®é¢˜æ˜¯å¦å·²ä¿®å¤
"""

import torch
import torch.nn.functional as F
from model import EFB

def test_model_forward():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­æ˜¯å¦äº§ç”ŸNaN"""
    print("æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    
    # åˆ›å»ºæ¨¡å‹
    model = EFB()
    model.eval()
    
    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥æ•°æ®
    batch_size = 4
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # æ¨¡æ‹Ÿå›¾åƒè¾“å…¥ (CLIP ViT-B/32 æœŸæœ› 224x224 å›¾åƒ)
    image = torch.randn(batch_size, 3, 224, 224).to(device)
    
    # æ¨¡æ‹Ÿæ–‡æœ¬è¾“å…¥ (CLIP tokenizer æœŸæœ›çš„æ ¼å¼)
    query = torch.randint(0, 49408, (batch_size, 77)).to(device)  # CLIP vocab size
    context = torch.randint(0, 49408, (batch_size, 77)).to(device)
    
    # æ¨¡æ‹Ÿæƒ…æ„Ÿè¾“å…¥ (BERT tokenizer æœŸæœ›çš„æ ¼å¼)
    emotion_ids = torch.randint(0, 21128, (batch_size, 32)).to(device)  # BERT vocab size
    emotion_mask = torch.ones(batch_size, 32).to(device)
    
    # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
    model = model.to(device)
    
    try:
        with torch.no_grad():
            # å‰å‘ä¼ æ’­
            outputs = model(image, query, context, emotion_ids, emotion_mask)
            
            sim_qi = outputs['sim_qi']
            sim_qc = outputs['sim_qc']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰NaN
            if torch.isnan(sim_qi).any():
                print("âŒ sim_qi åŒ…å« NaN å€¼")
                return False
            else:
                print("âœ… sim_qi æ²¡æœ‰ NaN å€¼")
                
            if torch.isnan(sim_qc).any():
                print("âŒ sim_qc åŒ…å« NaN å€¼")
                return False
            else:
                print("âœ… sim_qc æ²¡æœ‰ NaN å€¼")
            
            # æ‰“å°ç›¸ä¼¼åº¦çŸ©é˜µçš„èŒƒå›´
            print(f"sim_qi èŒƒå›´: [{sim_qi.min().item():.4f}, {sim_qi.max().item():.4f}]")
            print(f"sim_qc èŒƒå›´: [{sim_qc.min().item():.4f}, {sim_qc.max().item():.4f}]")
            
            # æµ‹è¯•æŸå¤±è®¡ç®—
            def test_loss(sim_matrix):
                batch_size = sim_matrix.size(0)
                labels = torch.arange(batch_size, device=sim_matrix.device)
                loss_rows = F.cross_entropy(sim_matrix, labels)
                loss_cols = F.cross_entropy(sim_matrix.t(), labels)
                return (loss_rows + loss_cols) / 2.0
            
            loss_qi = test_loss(sim_qi)
            loss_qc = test_loss(sim_qc)
            total_loss = loss_qi + loss_qc
            
            if torch.isnan(total_loss):
                print("âŒ æŸå¤±è®¡ç®—äº§ç”Ÿ NaN")
                return False
            else:
                print("âœ… æŸå¤±è®¡ç®—æ­£å¸¸")
                print(f"æ€»æŸå¤±: {total_loss.item():.4f}")
            
            return True
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_logit_scale():
    """æµ‹è¯• logit_scale å‚æ•°"""
    print("\næµ‹è¯• logit_scale å‚æ•°...")
    
    model = EFB()
    logit_scale = model.logit_scale
    
    print(f"logit_scale åˆå§‹å€¼: {logit_scale.item():.4f}")
    print(f"exp(logit_scale): {logit_scale.exp().item():.4f}")
    
    # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
    if logit_scale.exp().item() > 50:
        print("âš ï¸  logit_scale å¯èƒ½ä»ç„¶è¿‡å¤§")
    else:
        print("âœ… logit_scale åœ¨åˆç†èŒƒå›´å†…")

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯• NaN ä¿®å¤...")
    
    test_logit_scale()
    success = test_model_forward()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼NaN é—®é¢˜å·²ä¿®å¤ã€‚")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚") 